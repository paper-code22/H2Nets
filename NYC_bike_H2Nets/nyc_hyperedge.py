# -*- coding: utf-8 -*-
"""NYC_hyperedge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZEAz_CZjmMNImEGCXBYEgseS7yrs-Z6j
"""

!git clone https://github.com/tangxianfeng/STDN

from zipfile import ZipFile

with ZipFile('STDN/data.zip', 'r') as zipObj:
   # Extract all the contents of zip file in current directory
   zipObj.extractall()

import sys
import numpy as np
import pandas as pd

"""Data from Yao et al. "Revisiting spatial-temporal similarity: A deep learning framework for traffic prediction." Proceedings of the AAAI conference on artificial intelligence. Vol. 33. No. 01. 2019.

NYC-Taxi: NYC-Taxi dataset contains 22, 349, 490 taxi
trip records of NYC (nyc 2017b) in 2015, from
01/01/2015 to 03/01/2015. In the experiment, we use data
from 01/01/2015 to 02/10/2015 (40 days) as training data,
and the remained 20 days as testing data.
"""

flow_train = np.load(open("flow_train.npz", "rb"))["flow"] 
flow_test = np.load(open("flow_test.npz", "rb"))["flow"] 
volume_train = np.load(open("volume_train.npz", "rb"))["volume"] 
volume_test = np.load(open("volume_test.npz", "rb"))["volume"]
volume_train_max = volume_train.max()
volume_test_max = volume_test.max()
flow_train_max = flow_train.max()
flow_test_max = flow_test.max() 
flow_train.max(), flow_test.max(), volume_train.max(), volume_test.max()

flow_train.shape, flow_test.shape, volume_train.shape, volume_test.shape

"""NYC-Bike: The bike trajectories are collected from NYC
Citi Bike system (nyc 2017a) in 2016, from 07/01/2016
to 08/29/2016. The dataset contains 2, 605, 648 trip
records. The previous 40 days (i.e., from 07/01/2016 to
08/09/2016) are used as training data, and the rest 20 days
as testing data.
"""

bike_flow_train = np.load(open("bike_flow_train.npz", "rb"))["flow"] 
bike_flow_test = np.load(open("bike_flow_test.npz", "rb"))["flow"] 
bike_volume_train = np.load(open("bike_volume_train.npz", "rb"))["volume"] 
bike_volume_test = np.load(open("bike_volume_test.npz", "rb"))["volume"]
bike_volume_train_max = bike_volume_train.max()
bike_volume_test_max = bike_volume_test.max()
bike_flow_train_max = bike_flow_train.max()
bike_flow_test_max = bike_flow_test.max() 
bike_flow_train.max(), bike_flow_test.max(), bike_volume_train.max(), bike_volume_test.max()

bike_flow_train.shape, bike_flow_test.shape, bike_volume_train.shape, bike_volume_test.shape,

"""HGC-RNN paper builds 24*7 hyperedges of weekly hour groups and then merges them by Dice Similarity Coefficient (remaining hypergraph has a pairwise coefficient less than 0.8)

Yi and Park. "Hypergraph convolutional recurrent neural network." Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2020.
"""

# Sorensen-Dice coefficient
def DSC(h1, h2):
    n1 = sum(h1)
    n2 = sum(h2)
    n12 = sum(np.logical_and(h1, h2))
    return(2 * n12 / (n1 + n2))

"""without mask, median on volume > 10, maxDSC > 0.95"""

# # results for masked volume 0 
# totalvol = np.zeros((10,20))
# for i in range(1920):
#   half_hour_mask = volume_train[i,:,:,0] >= 10
#   totalvol = totalvol + volume_train[i,:,:,0] * half_hour_mask
# 
# mask = totalvol > 1017
# mask = dailyvol0 > 240*960/24
# remove nodes with daily volume <= 10
# set threshold = 0.96


vol = np.zeros((960,10,20))
for i in range(960):
  half_hour_mask1 = volume_train[2*i,:,:,0] >= 10
  half_hour_mask2 = volume_train[2*i+1,:,:,0] >= 10
  vol[i] = volume_train[2*i,:,:,0] * half_hour_mask1 + volume_train[2*i+1,:,:,0] * half_hour_mask2

nsamp = vol.shape[0]
hyperedge = np.zeros((7*24,200)) # 7*24 = 168
for i in range(7*24):
  j = i
  dat = np.zeros((10,20))
  while (j < nsamp):
    dat = dat + vol[j]
    # print(j)
    j = j + 7 *24
  # For the taxi demand data at a specific temporal group ð‘ž, we identify the regions > median
  hyperedge[i] = (dat>np.quantile(dat[dat>0],0.5)).reshape(1,-1)


maxDSC = 1
while maxDSC >= 0.05:
  sim = np.zeros((hyperedge.shape[0],hyperedge.shape[0]))
  for i in range(hyperedge.shape[0]):
    for j in range(i+1,hyperedge.shape[0]):
      sim[i,j] = DSC(hyperedge[i], hyperedge[j])  
  maxDSC = np.max(sim)
  if maxDSC >= 0.05:
    i1, i2 = np.unravel_index(np.argmax(sim, axis=None), sim.shape)
    hyperedge[i1] = np.logical_or(hyperedge[i1], hyperedge[i2])
    hyperedge[i2] = hyperedge[hyperedge.shape[0] - 1]
    hyperedge = np.delete(hyperedge, hyperedge.shape[0] - 1, axis=0)
    print(maxDSC, (i1,i2) , hyperedge.shape)

# # results for masked volume 0 
# totalvol = np.zeros((10,20))
# for i in range(1920):
#   half_hour_mask = volume_train[i,:,:,0] >= 10
#   totalvol = totalvol + volume_train[i,:,:,0] * half_hour_mask
# 
# mask = totalvol > 1017
# mask = dailyvol0 > 240*960/24
# remove nodes with daily volume <= 10
# set threshold = 0.96


vol = np.zeros((960,10,20))
for i in range(960):
  half_hour_mask1 = volume_train[2*i,:,:,0] >= 10
  half_hour_mask2 = volume_train[2*i+1,:,:,0] >= 10
  vol[i] = volume_train[2*i,:,:,0] * half_hour_mask1 + volume_train[2*i+1,:,:,0] * half_hour_mask2

nsamp = vol.shape[0]
hyperedge = np.zeros((7*24,200)) # 7*24 = 168
for i in range(7*24):
  j = i
  dat = np.zeros((10,20))
  while (j < nsamp):
    dat = dat + vol[j]
    # print(j)
    j = j + 7 *24
  # For the taxi demand data at a specific temporal group ð‘ž, we identify the regions > median
  hyperedge[i] = (dat>np.quantile(dat[dat>0],0.5)).reshape(1,-1)


maxDSC = 1
while maxDSC >= 0.95:
  sim = np.zeros((hyperedge.shape[0],hyperedge.shape[0]))
  for i in range(hyperedge.shape[0]):
    for j in range(i+1,hyperedge.shape[0]):
      sim[i,j] = DSC(hyperedge[i], hyperedge[j])  
  maxDSC = np.max(sim)
  if maxDSC >= 0.95:
    i1, i2 = np.unravel_index(np.argmax(sim, axis=None), sim.shape)
    hyperedge[i1] = np.logical_or(hyperedge[i1], hyperedge[i2])
    hyperedge[i2] = hyperedge[hyperedge.shape[0] - 1]
    hyperedge = np.delete(hyperedge, hyperedge.shape[0] - 1, axis=0)
    print(maxDSC, (i1,i2) , hyperedge.shape)

import seaborn as sns
import matplotlib.pylab as plt
figure, axis = plt.subplots(7,5)

for i in range(32):
  sns.heatmap(ax=axis[i%7,int(i/7)], data = hyperedge[i].reshape(10,20), vmax=.8, square = True)

# np.savez('HyperedgeWOavgMask.npz',hyperedge=hyperedge)
np.load(open("HyperedgeWOavgMask.npz", "rb"))["hyperedge"].sum(axis=1), np.load(open("HyperedgeWOavgMask.npz", "rb"))["hyperedge"].shape

"""with mask, median on volume > 10, maxDSC >= 0.96   """

# results for masked volume 0 
totalvol = np.zeros((10,20))
for i in range(1920):
  half_hour_mask = volume_train[i,:,:,0] >= 10
  totalvol = totalvol + volume_train[i,:,:,0] * half_hour_mask

mask = totalvol > 1017
# mask = dailyvol0 > 240*960/24
# remove nodes with daily volume <= 10
# set threshold = 0.96


vol = np.zeros((960,10,20))
for i in range(960):
  half_hour_mask1 = volume_train[2*i,:,:,0] >= 10
  half_hour_mask2 = volume_train[2*i+1,:,:,0] >= 10
  vol[i] = volume_train[2*i,:,:,0] * half_hour_mask1 + volume_train[2*i+1,:,:,0] * half_hour_mask2

nsamp = vol.shape[0]
hyperedge = np.zeros((7*24,200)) # 7*24 = 168
for i in range(7*24):
  j = i
  dat = np.zeros((10,20))
  while (j < nsamp):
    dat = dat + vol[j]
    # print(j)
    j = j + 7 *24
  # For the taxi demand data at a specific temporal group ð‘ž, we identify the regions > median
  maskdata = dat[mask]
  hyperedge[i] = (dat>np.quantile(maskdata[maskdata>0],0.5)).reshape(1,-1)


maxDSC = 1
while maxDSC >= 0.05:
  sim = np.zeros((hyperedge.shape[0],hyperedge.shape[0]))
  for i in range(hyperedge.shape[0]):
    for j in range(i+1,hyperedge.shape[0]):
      sim[i,j] = DSC(hyperedge[i], hyperedge[j])  
  maxDSC = np.max(sim)
  if maxDSC >= 0.05:
    i1, i2 = np.unravel_index(np.argmax(sim, axis=None), sim.shape)
    hyperedge[i1] = np.logical_or(hyperedge[i1], hyperedge[i2])
    hyperedge[i2] = hyperedge[hyperedge.shape[0] - 1]
    hyperedge = np.delete(hyperedge, hyperedge.shape[0] - 1, axis=0)
    print(maxDSC, (i1,i2) , hyperedge.shape)

# results for masked volume 0 
totalvol = np.zeros((10,20))
for i in range(1920):
  half_hour_mask = volume_train[i,:,:,0] >= 10
  totalvol = totalvol + volume_train[i,:,:,0] * half_hour_mask

mask = totalvol > 1017
# mask = dailyvol0 > 240*960/24
# remove nodes with daily volume <= 10
# set threshold = 0.96


vol = np.zeros((960,10,20))
for i in range(960):
  half_hour_mask1 = volume_train[2*i,:,:,0] >= 10
  half_hour_mask2 = volume_train[2*i+1,:,:,0] >= 10
  vol[i] = volume_train[2*i,:,:,0] * half_hour_mask1 + volume_train[2*i+1,:,:,0] * half_hour_mask2

nsamp = vol.shape[0]
hyperedge = np.zeros((7*24,200)) # 7*24 = 168
for i in range(7*24):
  j = i
  dat = np.zeros((10,20))
  while (j < nsamp):
    dat = dat + vol[j]
    # print(j)
    j = j + 7 *24
  # For the taxi demand data at a specific temporal group ð‘ž, we identify the regions > median
  maskdata = dat[mask]
  hyperedge[i] = (dat>np.quantile(maskdata[maskdata>0],0.5)).reshape(1,-1)


maxDSC = 1
while maxDSC >= 0.96:
  sim = np.zeros((hyperedge.shape[0],hyperedge.shape[0]))
  for i in range(hyperedge.shape[0]):
    for j in range(i+1,hyperedge.shape[0]):
      sim[i,j] = DSC(hyperedge[i], hyperedge[j])  
  maxDSC = np.max(sim)
  if maxDSC >= 0.96:
    i1, i2 = np.unravel_index(np.argmax(sim, axis=None), sim.shape)
    hyperedge[i1] = np.logical_or(hyperedge[i1], hyperedge[i2])
    hyperedge[i2] = hyperedge[hyperedge.shape[0] - 1]
    hyperedge = np.delete(hyperedge, hyperedge.shape[0] - 1, axis=0)
    print(maxDSC, (i1,i2) , hyperedge.shape)

import seaborn as sns
import matplotlib.pylab as plt
figure, axis = plt.subplots(7,5)

for i in range(34):
  sns.heatmap(ax=axis[i%7,int(i/7)], data = hyperedge[i].reshape(10,20), vmax=.8, square = True)

# np.savez('HyperedgeWithAvgMask.npz',hyperedge=hyperedge)
np.load(open("HyperedgeWithAvgMask.npz", "rb"))["hyperedge"].sum(axis=1), np.load(open("HyperedgeWithAvgMask.npz", "rb"))["hyperedge"].shape

"""# Bike data 

volume >= 10 threshold 0.9 -> 34 hyperedges

volume >= 0 threshold 0.93 -> 39 hyperedges
"""

# # results for masked volume 0 
# totalvol = np.zeros((10,20))
# for i in range(1920):
#   half_hour_mask = volume_train[i,:,:,0] >= 10
#   totalvol = totalvol + volume_train[i,:,:,0] * half_hour_mask
# 
# mask = totalvol > 1017
# mask = dailyvol0 > 240*960/24
# remove nodes with daily volume <= 10
# set threshold = 0.96


vol = np.zeros((960,10,20))
for i in range(960):
  half_hour_mask1 = bike_volume_train[2*i,:,:,0] >= 10
  half_hour_mask2 = bike_volume_train[2*i+1,:,:,0] >= 10
  vol[i] = bike_volume_train[2*i,:,:,0] * half_hour_mask1 + bike_volume_train[2*i+1,:,:,0] * half_hour_mask2
  

nsamp = vol.shape[0]
hyperedge = np.zeros((7*24,200)) # 7*24 = 168
for i in range(7*24):
  j = i
  dat = np.zeros((10,20))
  while (j < nsamp):
    dat = dat + vol[j]
    # print(j)
    j = j + 7 *24
  # For the taxi demand data at a specific temporal group ð‘ž, we identify the regions > median
  if dat.sum() > 0:
    hyperedge[i] = (dat>np.quantile(dat[dat>0],0.5)).reshape(1,-1)

hyperedge = hyperedge[hyperedge.sum(axis=1) > 0]
print(hyperedge.shape)

maxDSC = 1
while maxDSC >= 0.05:
  sim = np.zeros((hyperedge.shape[0],hyperedge.shape[0]))
  for i in range(hyperedge.shape[0]):
    for j in range(i+1,hyperedge.shape[0]):
      sim[i,j] = DSC(hyperedge[i], hyperedge[j])  
  maxDSC = np.max(sim)
  if maxDSC >= 0.05:
    i1, i2 = np.unravel_index(np.argmax(sim, axis=None), sim.shape)
    hyperedge[i1] = np.logical_or(hyperedge[i1], hyperedge[i2])
    hyperedge[i2] = hyperedge[hyperedge.shape[0] - 1]
    hyperedge = np.delete(hyperedge, hyperedge.shape[0] - 1, axis=0)
    print(maxDSC, (i1,i2) , hyperedge.shape)




vol = np.zeros((960,10,20))
for i in range(960):
  half_hour_mask1 = bike_volume_train[2*i,:,:,0] >= 10
  half_hour_mask2 = bike_volume_train[2*i+1,:,:,0] >= 10
  vol[i] = bike_volume_train[2*i,:,:,0] * half_hour_mask1 + bike_volume_train[2*i+1,:,:,0] * half_hour_mask2
  

nsamp = vol.shape[0]
hyperedge = np.zeros((7*24,200)) # 7*24 = 168
for i in range(7*24):
  j = i
  dat = np.zeros((10,20))
  while (j < nsamp):
    dat = dat + vol[j]
    # print(j)
    j = j + 7 *24
  # For the taxi demand data at a specific temporal group ð‘ž, we identify the regions > median
  if dat.sum() > 0:
    hyperedge[i] = (dat>np.quantile(dat[dat>0],0.5)).reshape(1,-1)

hyperedge = hyperedge[hyperedge.sum(axis=1) > 0]
print(hyperedge.shape)

maxDSC = 1
while maxDSC >= 0.9:
  sim = np.zeros((hyperedge.shape[0],hyperedge.shape[0]))
  for i in range(hyperedge.shape[0]):
    for j in range(i+1,hyperedge.shape[0]):
      sim[i,j] = DSC(hyperedge[i], hyperedge[j])  
  maxDSC = np.max(sim)
  if maxDSC >= 0.9:
    i1, i2 = np.unravel_index(np.argmax(sim, axis=None), sim.shape)
    hyperedge[i1] = np.logical_or(hyperedge[i1], hyperedge[i2])
    hyperedge[i2] = hyperedge[hyperedge.shape[0] - 1]
    hyperedge = np.delete(hyperedge, hyperedge.shape[0] - 1, axis=0)
    print(maxDSC, (i1,i2) , hyperedge.shape)

import seaborn as sns
import matplotlib.pylab as plt
figure, axis = plt.subplots(7,5)

for i in range(34):
  sns.heatmap(ax=axis[i%7,int(i/7)], data = hyperedge[i].reshape(10,20), vmax=.8, square = True)

# np.savez('bike_hyperedge_vol10.npz',hyperedge=hyperedge)
np.load(open("bike_hyperedge_vol10.npz", "rb"))["hyperedge"].sum(axis=1), np.load(open("bike_hyperedge_vol10.npz", "rb"))["hyperedge"].shape

# # results for masked volume 0 
# totalvol = np.zeros((10,20))
# for i in range(1920):
#   half_hour_mask = volume_train[i,:,:,0] >= 10
#   totalvol = totalvol + volume_train[i,:,:,0] * half_hour_mask
# 
# mask = totalvol > 1017
# mask = dailyvol0 > 240*960/24
# remove nodes with daily volume <= 10
# set threshold = 0.96


vol = np.zeros((960,10,20))
for i in range(960):
  vol[i] = bike_volume_train[2*i,:,:,0] + bike_volume_train[2*i+1,:,:,0] 
  

nsamp = vol.shape[0]
hyperedge = np.zeros((7*24,200)) # 7*24 = 168
for i in range(7*24):
  j = i
  dat = np.zeros((10,20))
  while (j < nsamp):
    dat = dat + vol[j]
    # print(j)
    j = j + 7 *24
  # For the taxi demand data at a specific temporal group ð‘ž, we identify the regions > median
  hyperedge[i] = (dat>np.quantile(dat[dat>0],0.5)).reshape(1,-1)

maxDSC = 1
while maxDSC >= 0.05:
  sim = np.zeros((hyperedge.shape[0],hyperedge.shape[0]))
  for i in range(hyperedge.shape[0]):
    for j in range(i+1,hyperedge.shape[0]):
      sim[i,j] = DSC(hyperedge[i], hyperedge[j])  
  maxDSC = np.max(sim)
  if maxDSC >= 0.05:
    i1, i2 = np.unravel_index(np.argmax(sim, axis=None), sim.shape)
    hyperedge[i1] = np.logical_or(hyperedge[i1], hyperedge[i2])
    hyperedge[i2] = hyperedge[hyperedge.shape[0] - 1]
    hyperedge = np.delete(hyperedge, hyperedge.shape[0] - 1, axis=0)
    print(maxDSC, (i1,i2) , hyperedge.shape)

# # results for masked volume 0 
# totalvol = np.zeros((10,20))
# for i in range(1920):
#   half_hour_mask = volume_train[i,:,:,0] >= 10
#   totalvol = totalvol + volume_train[i,:,:,0] * half_hour_mask
# 
# mask = totalvol > 1017
# mask = dailyvol0 > 240*960/24
# remove nodes with daily volume <= 10
# set threshold = 0.96


vol = np.zeros((960,10,20))
for i in range(960):
  vol[i] = bike_volume_train[2*i,:,:,0] + bike_volume_train[2*i+1,:,:,0] 
  

nsamp = vol.shape[0]
hyperedge = np.zeros((7*24,200)) # 7*24 = 168
for i in range(7*24):
  j = i
  dat = np.zeros((10,20))
  while (j < nsamp):
    dat = dat + vol[j]
    # print(j)
    j = j + 7 *24
  # For the taxi demand data at a specific temporal group ð‘ž, we identify the regions > median
  hyperedge[i] = (dat>np.quantile(dat[dat>0],0.5)).reshape(1,-1)

maxDSC = 1
while maxDSC >= 0.93:
  sim = np.zeros((hyperedge.shape[0],hyperedge.shape[0]))
  for i in range(hyperedge.shape[0]):
    for j in range(i+1,hyperedge.shape[0]):
      sim[i,j] = DSC(hyperedge[i], hyperedge[j])  
  maxDSC = np.max(sim)
  if maxDSC >= 0.93:
    i1, i2 = np.unravel_index(np.argmax(sim, axis=None), sim.shape)
    hyperedge[i1] = np.logical_or(hyperedge[i1], hyperedge[i2])
    hyperedge[i2] = hyperedge[hyperedge.shape[0] - 1]
    hyperedge = np.delete(hyperedge, hyperedge.shape[0] - 1, axis=0)
    print(maxDSC, (i1,i2) , hyperedge.shape)

import seaborn as sns
import matplotlib.pylab as plt
figure, axis = plt.subplots(8,5)

for i in range(39):
  sns.heatmap(ax=axis[i%8,int(i/8)], data = hyperedge[i].reshape(10,20), vmax=.8, square = True)

# np.savez('bike_hyperedge.npz',hyperedge=hyperedge)
np.load(open("bike_hyperedge.npz", "rb"))["hyperedge"].sum(axis=1), np.load(open("bike_hyperedge.npz", "rb"))["hyperedge"].shape